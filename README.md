# Computational Social Science with Images and Audio

Welcome! This is the GitHub page for my class "Computational Social Science with Images and Audio" at ETH Zurich.

## Objectives

This course introduces a broad array of computer vision and audio analysis tools. Students will learn to apply these tools to a variety of problems. The applications will focus on social science contexts, including economics, politics, and law. Students will learn how to featurize audio and visual content, build models based on these features (e.g., for classification), and evaluate the models -- both in terms of performance and societal implications.

<p align="center">
  <img src="https://github.com/philinew/css_images_audio/blob/main/data/design/dalle1.png" width="39%" />
  <br>
  <i>Picture by Dall-E, prompted to give "a symbol for computational social science".</i>
</p>

<p align="center">
  <img src="https://github.com/philinew/css_images_audio/blob/main/data/design/dalle2.png" width="39%" />
  <br>
  <i>Picture by Dall-E, prompted to give an "artwork symbolizing computational social science".</i>
</p>

## Content

Audio analysis and computer vision technologies have a considerable potential to generate new insights in the social sciences and assist decision-makers in various policy-relevant positions. At the same time, there are risks of adverse effects. For instance, such technologies could engrain or reinforce bias. They could also be abused, e.g., for surveillance or fraudulent/fake representations (such as deep fakes). The course enables students to develop their own projects involving audio and visual content and critically assess recent developments in these technologies.

## Prerequisites

Some Python programming skills are required (or a strong willingness to acquire these skills on the go). Some experience with text, image, or audio analysis is valuable but not required.

